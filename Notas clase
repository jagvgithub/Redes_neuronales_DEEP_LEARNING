# clase 1
# 4 entregas actividades.


# 24/09/2024

Se ajustarÃ¡n las fechas de las actividades.

- Problemas de regresiÃ³n y clasificaciÃ³n 
(modelo de predicciÃ³n - combinaciÃ³n (fontera lineal) lineal de multiples variables)
cuando no son lineales se hace necesario usar redes neuronales.

Capa de entrada - capas ocultas - capa de salida
Cada neurona tiene unos pesos

- FunciÃ³n de activaciÃ³n

- Backward propagation (prueba y feedback) # tetester que tan bien estÃ¡ prediciendo la red.
sirve para determinar el error y asÃ­ calibrar la red
ajustando los pesos para que la predicciÃ³n sea mejor.

- Regla de la cadena.
- tasa de aprendizaje (learning rate)

- back propagation (ajuste de pesos)

A medida que las redes neuronales los costos computacionales son mÃ¡s complejos 

######### terminos importantes 

- forward, backward propagation,parÃ¡metros,pesos,regla de la cadena, descenso del gradiente.


Forward Propagation (PropagaciÃ³n Hacia Adelante): Es el proceso de pasar la entrada a travÃ©s de la red neuronal para obtener una predicciÃ³n. 
En cada capa, se aplican pesos y funciones de activaciÃ³n a los datos, transformando la entrada hasta llegar a la capa de salida.

Backward Propagation (PropagaciÃ³n Hacia AtrÃ¡s): Es el proceso de ajustar los pesos de la red despuÃ©s de calcular el error entre la predicciÃ³n y el valor real. 
Se utiliza para minimizar el error a travÃ©s de la regla de la cadena, calculando los gradientes y actualizando los pesos en la direcciÃ³n opuesta al gradiente.

ParÃ¡metros: Son las variables que la red neuronal ajusta durante el entrenamiento para aprender a hacer predicciones. Incluyen los pesos y los sesgos 
que se aplican a las entradas en cada neurona.

Pesos: Son los coeficientes que determinan la influencia de cada entrada en la salida de una neurona. Los pesos son actualizados durante 
el entrenamiento para mejorar la precisiÃ³n de las predicciones.

Regla de la Cadena: Es una fÃ³rmula en cÃ¡lculo que permite calcular la derivada de funciones compuestas. 
En el contexto de redes neuronales, se usa durante la propagaciÃ³n hacia atrÃ¡s para calcular cÃ³mo un cambio en los pesos afecta al error final.

Descenso del Gradiente: Es un algoritmo de optimizaciÃ³n utilizado para minimizar la funciÃ³n de pÃ©rdida. 
Consiste en ajustar los pesos en la direcciÃ³n opuesta al gradiente de la funciÃ³n de pÃ©rdida, buscando asÃ­ los valores Ã³ptimos de los
parÃ¡metros que reducen el error de predicciÃ³n.

AND lineal
XOR no lineal 


TIPOS de DESCENSO DEL GRADIENTE
- stocastic gradient descent: size 1
- Mini- batch SGD : size >1 < tamaÃ±o del training set
- Batch SGD: batch size == tamaÃ±o del trainig set

Stochastic Gradient Descent (SGD): Este mÃ©todo actualiza los pesos utilizando solo un ejemplo (tamaÃ±o de lote de 1) en cada iteraciÃ³n. 
Esto hace que las actualizaciones sean muy rÃ¡pidas, pero tambiÃ©n introduce variabilidad, ya que cada ejemplo puede llevar a una direcciÃ³n
diferente en el espacio de parÃ¡metros.

Mini-Batch Gradient Descent: En este enfoque, se utiliza un pequeÃ±o grupo de ejemplos (batch) para actualizar los pesos. 
El tamaÃ±o del batch es mayor que 1 pero menor que el tamaÃ±o total del conjunto de entrenamiento. Esto proporciona un buen 
equilibrio entre la rapidez del SGD y la estabilidad del Batch Gradient Descent.

Batch Gradient Descent: AquÃ­, se utilizan todos los ejemplos del conjunto de entrenamiento (batch size igual al tamaÃ±o del conjunto de entrenamiento)
para calcular la actualizaciÃ³n de los pesos. Aunque es mÃ¡s estable y proporciona una direcciÃ³n mÃ¡s precisa para la actualizaciÃ³n, puede ser lento 
y consumir mucha memoria, especialmente con conjuntos de datos grandes.

Descenso del gradiente : OPTIMIZADOR.

############## FUNCIONES DE ACTIVACION #############

- RELU : valor negativo de salida, el valor con la funciÃ³n toma cero
- SIGMOIDE : acota el rango de salida entre cero y uno
- SOFTMAX
- TANH

ReLU (Rectified Linear Unit)
DefiniciÃ³n: La funciÃ³n ReLU es definida como 
ð‘“
(
ð‘¥
)
=
max
â¡
(
0
,
ð‘¥
)
f(x)=max(0,x). Esto significa que para cualquier valor de entrada negativo, la salida es cero; para valores positivos, la salida es igual al valor de entrada.

Ventajas:

Computacionalmente eficiente (no requiere operaciones exponenciales).
Ayuda a mitigar el problema del desvanecimiento del gradiente, permitiendo que los gradientes fluyan mÃ¡s fÃ¡cilmente.
Desventajas:

Puede sufrir del problema "dropped neurons", donde ciertas neuronas dejan de activarse completamente (salida siempre cero) durante el entrenamiento.
No estÃ¡ acotada, lo que puede llevar a salidas muy grandes.
2. Sigmoide
DefiniciÃ³n: La funciÃ³n sigmoide se define como 
ð‘“
(
ð‘¥
)
=
1
1
+
ð‘’
âˆ’
ð‘¥
f(x)= 
1+e 
âˆ’x
 
1
â€‹
 . Mapea cualquier valor real a un rango entre 0 y 1.

Ventajas:

Buena para modelar probabilidades y resultados binarios.
Su salida estÃ¡ acotada, lo que hace que sea fÃ¡cil interpretar como probabilidad.
Desventajas:

Puede sufrir del problema del desvanecimiento del gradiente, lo que dificulta el entrenamiento de redes profundas.
La salida no estÃ¡ centrada en cero, lo que puede causar problemas de convergencia.
3. Softmax
DefiniciÃ³n: La funciÃ³n Softmax se usa principalmente en la capa de salida de modelos de clasificaciÃ³n multiclase. Convierte un vector de valores reales en probabilidades que suman 1, usando la fÃ³rmula 
ð‘“
(
ð‘¥
ð‘–
)
=
ð‘’
ð‘¥
ð‘–
âˆ‘
ð‘—
ð‘’
ð‘¥
ð‘—
f(x 
i
â€‹
 )= 
âˆ‘ 
j
â€‹
 e 
x 
j
â€‹
 
 
e 
x 
i
â€‹
 
 $fdfdfdsfdsf$
â€‹
 .

Ventajas:

Ideal para clasificaciÃ³n multiclase, ya que produce probabilidades que son interpretables.
Ayuda a seleccionar la clase con la mayor probabilidad al final del modelo.
Desventajas:

Puede ser sensible a valores extremos, lo que puede afectar la estabilidad numÃ©rica.
No es adecuada para problemas que no requieren una salida de probabilidad.
4. Tanh (Tangente HiperbÃ³lica)
DefiniciÃ³n: La funciÃ³n tanh se define como 
ð‘“
(
ð‘¥
)
=
ð‘’
ð‘¥
âˆ’
ð‘’
âˆ’
ð‘¥
ð‘’
ð‘¥
+
ð‘’
âˆ’
ð‘¥
f(x)= 
e 
x
 +e 
âˆ’x
 
e 
x
 âˆ’e 
âˆ’x
 
â€‹
 . Mapea cualquier valor real a un rango entre -1 y 1.

Ventajas:

EstÃ¡ centrada en cero, lo que puede acelerar la convergencia.
Menos susceptible al problema del desvanecimiento del gradiente en comparaciÃ³n con la sigmoide.
Desventajas:

AÃºn puede sufrir el problema del desvanecimiento del gradiente para valores extremos.
La computaciÃ³n puede ser mÃ¡s costosa que ReLU, ya que implica operaciones exponenciales.







